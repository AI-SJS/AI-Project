# ğŸ©º í‰ë¶€ X-ray ë³‘ë³€ ê°ì§€ ë° ë¦¬í¬íŠ¸ ìƒì„± ì‹œìŠ¤í…œ  
### ë”¥ëŸ¬ë‹ ëª¨ë¸ê³¼ ì‹œê°í™” ê¸°ìˆ ì„ í™œìš©í•œ MIMIC-CXR ê¸°ë°˜ ìë™ íŒë… ì†Œê²¬ ìƒì„±

---

## ğŸ“Œ Motivation

> â€œì•” ê´€ë ¨ í”¼í•´êµ¬ì œ ì‹ ì²­ 3ê±´ ì¤‘ 1ê±´ì€ â€˜ì˜¤ì§„â€™â€ â€“ ë‰´ìŠ¤ì›° (2021)

ì˜ë£Œ ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì˜ ë°œì „ì—ë„ ë¶ˆêµ¬í•˜ê³ , **ë°©ì‚¬ì„  ì˜ìƒ íŒë…ì˜ ì˜¤ë¥˜ ë° ì˜¤ì§„ ë¬¸ì œ**ëŠ” ì—¬ì „íˆ ì‹¬ê°í•©ë‹ˆë‹¤.  
ì´ì— ë”°ë¼, **ì •í™•í•˜ê³  ìë™í™”ëœ ì˜ë£Œ ë¦¬í¬íŠ¸ ìƒì„± ì‹œìŠ¤í…œ**ì˜ í•„ìš”ì„±ì´ ë†’ì•„ì§€ê³  ìˆìœ¼ë©°, ë³¸ ì—°êµ¬ëŠ” í‰ë¶€ X-rayë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¦¬í¬íŠ¸ ìƒì„± ëª¨ë¸ì„ ë¹„êµ ë¶„ì„í•©ë‹ˆë‹¤.

<img width="519" alt="image" src="https://github.com/user-attachments/assets/036cca89-47b1-4333-bd9f-c8e21646b270" />
<img width="480" alt="image" src="https://github.com/user-attachments/assets/c410c932-4824-4bb0-935f-d323741e9fc8" />
<img width="400" alt="image" src="https://github.com/user-attachments/assets/aaf8bf12-2bbe-4302-8e88-bb93093f4200" />
<img width="550" alt="image" src="https://github.com/user-attachments/assets/d62fb75f-e8f9-4230-9712-325886f4627b" />

---

## ğŸ” Related Work

1. **Vision-Language ê¸°ë°˜ í”„ë ˆì„ì›Œí¬**
   - ArÄ±soy et al. (2025): ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ê¸°ë°˜ ìë™ ë³´ê³ ì„œ ìƒì„± êµ¬ì¡° ì œì•ˆ
   - <img width="476" alt="image" src="https://github.com/user-attachments/assets/cc5c1e41-5476-48cc-a7c1-fc7fff28488e" />


2. **Transformer ê¸°ë°˜ ë¦¬í¬íŠ¸ ìƒì„±**
   - Agarwal & Verma (2025): ViTì™€ GPT-4 í™œìš©í•œ ìë™ ë¦¬í¬íŠ¸ ìƒì„± êµ¬ì¡° ì„¤ê³„
   - <img width="444" alt="image" src="https://github.com/user-attachments/assets/8d098b55-ee7a-4c65-bc36-b9ddeba52e6c" />


3. **Memory-driven Transformer**
   - Chen et al. (2020): ë¦¬í¬íŠ¸ ë‚´ ì •ë³´ ì—°ê²° ê°•í™”ë¥¼ ìœ„í•œ ë©”ëª¨ë¦¬ ê¸°ë°˜ ëª¨ë¸
   - <img width="354" alt="image" src="https://github.com/user-attachments/assets/6be34b99-ea65-4269-a7ac-13efdb028ede" />


4. **Anatomical Attention ê¸°ë°˜ ëª¨ë¸**
   - Nguyen et al. (2025): í•´ë¶€í•™ì  ì •ë ¬ ê¸°ë°˜ ë¦¬í¬íŠ¸ ìƒì„±ìœ¼ë¡œ ì¤‘ìš”í•œ ë¶€ìœ„ ê°•ì¡°
   - <img width="333" alt="image" src="https://github.com/user-attachments/assets/f38f0ad0-6cf8-4690-bb59-813855818cc2" />

---

## âš™ï¸ Experimental Environment

- **Dataset**: [MIMIC-CXR](https://physionet.org/content/mimic-cxr/2.0.0/)
  > í‰ë¶€ X-rayì™€ ë°©ì‚¬ì„  ì „ë¬¸ì˜ ë¦¬í¬íŠ¸ê°€ 1:1ë¡œ ë§¤ì¹­ëœ ëŒ€ê·œëª¨ ì˜ë£Œ ë°ì´í„°ì…‹
  > <img width="784" alt="image" src="https://github.com/user-attachments/assets/f13ce814-368f-4b64-b46d-ff9ddfa1f296" />


- **Fine-Tuning ëª¨ë¸**:

- <img width="1037" alt="image" src="https://github.com/user-attachments/assets/52c53d9f-425c-4bca-905b-f351d566ca22" />

- **í•˜ë“œì›¨ì–´**:
  - <img width="487" alt="image" src="https://github.com/user-attachments/assets/e2e2557d-1808-4826-869f-ee2870a408b0" />


- **ë°ì´í„° ì‚¬ìš© ë¹„ìœ¨ ë° í‰ê°€ì§€í‘œ**:
  - 25%, 50%, 75%, 100%ë¡œ ì¦ë¶„ ì‹¤í—˜ ìˆ˜í–‰
  - <img width="538" alt="image" src="https://github.com/user-attachments/assets/4fb5354c-9135-4f7e-a7e1-bf697cf57f6e" />


---

## ğŸ§ª Experimental Results

### ğŸ“Š í•™ìŠµ ì´ë¯¸ì§€ ì‚¬ìš©ëŸ‰ê³¼ ëª¨ë¸ì— ë”°ë¥¸ ì„±ëŠ¥ ë¹„êµ (í‘œ 9)

| Model  | IMAGE Volume (%) | BL-1   | BL-2   | BL-3   | BL-4   | MTR    | RG-L   | AVG. â–³   |
|--------|------------------|--------|--------|--------|--------|--------|--------|-----------|
| **R2Gen** | 25%              | 0.1900 | 0.1072 | 0.0667 | 0.0450 | 0.0874 | 0.2245 | -         |
|        | 50%              | 0.2411 | 0.1411 | 0.0906 | 0.0622 | 0.1066 | 0.2431 | 22.81%    |
|        | 75%              | 0.2484 | 0.1441 | 0.0922 | 0.0634 | 0.1068 | 0.2442 | 24.74%    |
|        | 100%             | **0.2738** | **0.1615** | **0.1038** | **0.0712** | **0.1139** | **0.2500** | **35.22%** |
| **A3Net** | 25%              | 0.2174 | 0.1207 | 0.0737 | 0.0490 | 0.0966 | 0.2277 | -         |
|        | 50%              | 0.2576 | 0.1446 | 0.0891 | 0.0590 | 0.1101 | 0.2397 | 14.72%    |
|        | 75%              | 0.2760 | 0.1540 | 0.0948 | 0.0637 | 0.1140 | 0.2388 | 19.89%    |
|        | 100%             | **0.3011** | **0.1736** | **0.1098** | **0.0739** | **0.1250** | **0.2513** | **31.99%** |

> âœ… **A3Net**ì€ ëª¨ë“  ë°ì´í„° ë¹„ìœ¨ì—ì„œ R2Genë³´ë‹¤ ì „ë°˜ì ìœ¼ë¡œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìœ¼ë©°,  
> íŠ¹íˆ BLEU-4, MTR, ROUGE-L ì§€í‘œì—ì„œì˜ ìƒìŠ¹ í­ì´ ì»¸ìŠµë‹ˆë‹¤.


### ğŸ§¾ ì‹¤ì œ ì˜ì‚¬ ë¦¬í¬íŠ¸ vs ìƒì„± ë¦¬í¬íŠ¸ ë¹„êµ
- <img width="1044" alt="image" src="https://github.com/user-attachments/assets/cabe431b-7ce4-4cbc-80a8-3ad82269d414" />

### ğŸ” ì£¼ìš” ë¶„ì„
- ë°ì´í„°ê°€ ë§ì„ìˆ˜ë¡ ì„±ëŠ¥ í–¥ìƒ í­ ì¦ê°€
- A3Netì€ anatomy ê¸°ë°˜ attentionìœ¼ë¡œ ë” ì •êµí•œ ë¦¬í¬íŠ¸ ìƒì„±
- ### ğŸ§  R2Gen vs A3Net ëª¨ë¸ ë¹„êµ

| í•­ëª©             | R2Gen | A3Net | A3Netì´ ë” ìš°ìˆ˜í•œ ì´ìœ  |
|------------------|--------|--------|------------------------|
| **ê¸°ë³¸ êµ¬ì¡°**     | CNN + Transformer<br>Encoder-Decoder | CNN + Transformer<br>+ Cross-modal Memory Network (CMM) | **ë©€í‹°ëª¨ë‹¬ ì •ë³´ í†µí•© ê°•í™”** |
| **ì´ë¯¸ì§€ ì¸ì½”ë”** | ResNet ê¸°ë°˜ CNN<br>â†’ global feature ì¶”ì¶œ | ResNet ê¸°ë°˜ CNN<br>â†’ Memory ì €ì¥<br>â†’ Cross-modal attentionì— í™œìš© | **ì´ë¯¸ì§€ ì •ë³´ì˜ í™œìš© ë²”ìœ„ì™€ í•´ì„ë ¥ â†‘** |
| **í…ìŠ¤íŠ¸ ë””ì½”ë”** | Transformer Decoder | Transformer Decoder + CMM | **ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ëŒ€ì‘ ê´€ê³„ë¥¼ ê¸°ì–µí•˜ê³  ì¬ì°¸ì¡°** |
| **Attention ë°©ì‹** | Self-attention | Cross-attention<br>+ Memory-attention | **ë¬¸ë§¥ ê¸°ë°˜ ë””ì½”ë”© ê°€ëŠ¥** |

### ğŸ©» ë¦¬í¬íŠ¸ ë¬¸ì¥ ë¶„ì„: R2Gen vs A3Net

| í•­ëª© | R2Gen | A3Net | ì„¤ëª… |
|------|--------|--------|------|
| **ì €íìš©ì **<br>(Low lung volume) | ê°„ë‹¨ ì„¤ëª… | êµ¬ì¡°ì  ì„¤ëª… ì¶”ê°€ | **A3Net**:<br>â€œlow lung volumesâ€ë¿ ì•„ë‹ˆë¼,<br>ê·¸ ì›ì¸ì¸ â€œsecondary crowding of bronchovascular markingsâ€ê¹Œì§€ ëª…ì‹œ |
| **í‰ìˆ˜**<br>(Pleural Effusion) | ëª¨í˜¸í•œ í‘œí˜„ | ì •í™•í•œ í•´ë¶€í•™ í‘œí˜„ | **R2Gen**: â€œbibasilar opacitiesâ€ (ì–‘ì¸¡ ê¸°ì €ë¶€ ìŒì˜)<br>**A3Net**: â€œblunting of the costophrenic angleâ€ (ëŠ‘íš¡ê²©ê° ë‘”í™”) |
| **íê²½í™”**<br>(Consolidation) | ëª…ì‹œ ì—†ìŒ | ëª…ì‹œ ìˆìŒ | **A3Net**:<br>Ground-truthì™€ ìœ ì‚¬í•˜ê²Œ â€œno confluent consolidationâ€ ëª…ì‹œí•˜ë©°<br>pneumonia(íë ´) ë°°ì œí•˜ëŠ” í‘œí˜„ í¬í•¨ |
| **ë¬¸ì¥ êµ¬ì¡°/ìŠ¤íƒ€ì¼**<br>(Sentence Structure/Style) | ë‹¨ìˆœ ë‚˜ì—´ | ì˜ë£Œ ë³´ê³ ì„œ ìŠ¤íƒ€ì¼ | **A3Net**:<br>ë” ì •ëˆëœ ë¬¸ì¥ êµ¬ì¡°ì˜ ë¦¬í¬íŠ¸ ìƒì„± |


---

## âœ… Conclusion

- ë°ì´í„° ì‚¬ìš©ëŸ‰ ì¦ê°€ê°€ ëª¨ë¸ ì„±ëŠ¥ì— **ì§ì ‘ì ì¸ ì˜í–¥**ì„ ë¯¸ì¹¨
- A3Netì€ **ë¦¬í¬íŠ¸ ë‚´ í•´ë¶€í•™ì  ì¼ê´€ì„±** ì¸¡ë©´ì—ì„œ ìš°ìˆ˜í•œ ê²°ê³¼ë¥¼ ë³´ì„
- í–¥í›„ ë” ë³µí•©ì ì¸ Transformer êµ¬ì¡°ë‚˜ VLM ëª¨ë¸ ê²°í•© ê°€ëŠ¥ì„± ì¡´ì¬

---

## ğŸš€ Future Work

- ViT-GPT ê¸°ë°˜ ë©€í‹°ëª¨ë‹¬ êµ¬ì¡° ë„ì…
- ë³‘ë³€ ì‹œê°í™” (Grad-CAM ë“±) ê¸°ë°˜ LLM ë¦¬í¬íŠ¸ ì •êµí™”
- ë‹¤ì–‘í•œ ì§ˆë³‘/í´ë˜ìŠ¤ì— ëŒ€í•œ generalization ì„±ëŠ¥ í™•ì¸

---

## ğŸ‘¨â€ğŸ’» Contributors

- ì„œì¬ì„ (Konyang Univ., Dept. of Artificial Intelligence)  
- ì¥ê·¼í˜ (Konyang Univ., Dept. of Artificial Intelligence)  

Contact:  
- vhvh1398@naver.com  
- forren0418@naver.com

---

## ğŸ“š References

1. M. Varol ArÄ±soy et al., *A vision attention driven Language framework for medical report generation*, Scientific Reports, 2025.  
2. L. Agarwal and B. Verma, *Advanced Chest X-Ray Analysis via Transformer-Based Image Descriptors*, arXiv:2504.16774  
3. Z. Chen et al., *Generating Radiology Reports via Memory-driven Transformer*, EMNLP, 2020  
4. Q. V. Nguyen et al., *Anatomical Attention Alignment*, arXiv:2505.07689  
5. A. Johnson et al., *MIMIC-CXR: A large publicly available database*, NeurIPS ML4H, 2019
