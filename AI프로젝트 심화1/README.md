# ğŸ©º í‰ë¶€ X-ray ë³‘ë³€ ê°ì§€ ë° ë¦¬í¬íŠ¸ ìƒì„± ì‹œìŠ¤í…œ  
### ë”¥ëŸ¬ë‹ ëª¨ë¸ê³¼ ì‹œê°í™” ê¸°ìˆ ì„ í™œìš©í•œ MIMIC-CXR ê¸°ë°˜ ìë™ íŒë… ì†Œê²¬ ìƒì„±

---

## ğŸ“Œ Motivation

> â€œì•” ê´€ë ¨ í”¼í•´êµ¬ì œ ì‹ ì²­ 3ê±´ ì¤‘ 1ê±´ì€ â€˜ì˜¤ì§„â€™â€ â€“ ë‰´ìŠ¤ì›° (2021)

ì˜ë£Œ ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì˜ ë°œì „ì—ë„ ë¶ˆêµ¬í•˜ê³ , **ë°©ì‚¬ì„  ì˜ìƒ íŒë…ì˜ ì˜¤ë¥˜ ë° ì˜¤ì§„ ë¬¸ì œ**ëŠ” ì—¬ì „íˆ ì‹¬ê°í•©ë‹ˆë‹¤.  
ì´ì— ë”°ë¼, **ì •í™•í•˜ê³  ìë™í™”ëœ ì˜ë£Œ ë¦¬í¬íŠ¸ ìƒì„± ì‹œìŠ¤í…œ**ì˜ í•„ìš”ì„±ì´ ë†’ì•„ì§€ê³  ìˆìœ¼ë©°, ë³¸ ì—°êµ¬ëŠ” í‰ë¶€ X-rayë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¦¬í¬íŠ¸ ìƒì„± ëª¨ë¸ì„ ë¹„êµ ë¶„ì„í•©ë‹ˆë‹¤.

---

## ğŸ” Related Work

1. **Vision-Language ê¸°ë°˜ í”„ë ˆì„ì›Œí¬**
   - ArÄ±soy et al. (2025): ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ê¸°ë°˜ ìë™ ë³´ê³ ì„œ ìƒì„± êµ¬ì¡° ì œì•ˆ

2. **Transformer ê¸°ë°˜ ë¦¬í¬íŠ¸ ìƒì„±**
   - Agarwal & Verma (2025): ViTì™€ GPT-4 í™œìš©í•œ ìë™ ë¦¬í¬íŠ¸ ìƒì„± êµ¬ì¡° ì„¤ê³„

3. **Memory-driven Transformer**
   - Chen et al. (2020): ë¦¬í¬íŠ¸ ë‚´ ì •ë³´ ì—°ê²° ê°•í™”ë¥¼ ìœ„í•œ ë©”ëª¨ë¦¬ ê¸°ë°˜ ëª¨ë¸

4. **Anatomical Attention ê¸°ë°˜ ëª¨ë¸**
   - Nguyen et al. (2025): í•´ë¶€í•™ì  ì •ë ¬ ê¸°ë°˜ ë¦¬í¬íŠ¸ ìƒì„±ìœ¼ë¡œ ì¤‘ìš”í•œ ë¶€ìœ„ ê°•ì¡°

ğŸ“Œ ê° ëª¨ë¸ì˜ êµ¬ì¡°ì™€ í•œê³„ì ì€ PPT ë‚´ í‘œ 1, 2 ì°¸ê³ 

---

## âš™ï¸ Experimental Environment

- **Dataset**: [MIMIC-CXR](https://physionet.org/content/mimic-cxr/2.0.0/)
  > í‰ë¶€ X-rayì™€ ë°©ì‚¬ì„  ì „ë¬¸ì˜ ë¦¬í¬íŠ¸ê°€ 1:1ë¡œ ë§¤ì¹­ëœ ëŒ€ê·œëª¨ ì˜ë£Œ ë°ì´í„°ì…‹

- **Fine-Tuning ëª¨ë¸**:
  - R2Gen
  - A3Net

- **í•˜ë“œì›¨ì–´**:
  - GPU í™˜ê²½ ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ êµ¬ì„±ì€ PPT í‘œ 6 ì°¸ê³ 

- **ë°ì´í„° ì‚¬ìš© ë¹„ìœ¨**:
  - 25%, 50%, 75%, 100%ë¡œ ì¦ë¶„ ì‹¤í—˜ ìˆ˜í–‰

---

## ğŸ§ª Experimental Results

### ğŸ“ˆ í•™ìŠµ ì´ë¯¸ì§€ ë¹„ìœ¨ë³„ ì„±ëŠ¥ ë¹„êµ

| ì‚¬ìš©ëŸ‰ (%) | Model  | ì£¼ìš” ì„±ëŠ¥ (BLEU, ROUGE ë“±) |
|------------|--------|-----------------------------|
| 25%        | R2Gen  | ğŸ“Š ìˆ˜ì¹˜ ì…ë ¥ ì˜ˆì •           |
|            | A3Net  | ğŸ“Š ìˆ˜ì¹˜ ì…ë ¥ ì˜ˆì •           |
| 50%        | R2Gen  | ğŸ“Š ìˆ˜ì¹˜ ì…ë ¥ ì˜ˆì •           |
|            | A3Net  | ğŸ“Š ìˆ˜ì¹˜ ì…ë ¥ ì˜ˆì •           |
| 75%        | R2Gen  | ğŸ“Š ìˆ˜ì¹˜ ì…ë ¥ ì˜ˆì •           |
|            | A3Net  | ğŸ“Š ìˆ˜ì¹˜ ì…ë ¥ ì˜ˆì •           |
| 100%       | R2Gen  | ğŸ“Š ìˆ˜ì¹˜ ì…ë ¥ ì˜ˆì •           |
|            | A3Net  | ğŸ“Š ìˆ˜ì¹˜ ì…ë ¥ ì˜ˆì •           |

### ğŸ§¾ ì‹¤ì œ ì˜ì‚¬ ë¦¬í¬íŠ¸ vs ìƒì„± ë¦¬í¬íŠ¸ ë¹„êµ
- ì˜ˆì‹œ: Pneumothorax í™˜ìì˜ ë¦¬í¬íŠ¸ ë¹„êµ (PPT ê·¸ë¦¼ 6)

### ğŸ” ì£¼ìš” ë¶„ì„
- ë°ì´í„°ê°€ ë§ì„ìˆ˜ë¡ ì„±ëŠ¥ í–¥ìƒ í­ ì¦ê°€
- A3Netì€ anatomy ê¸°ë°˜ attentionìœ¼ë¡œ ë” ì •êµí•œ ë¦¬í¬íŠ¸ ìƒì„±
- í‘œ 11, 12ë¥¼ í†µí•´ ëª¨ë¸ êµ¬ì¡°ì™€ ì˜ˆì¸¡ ë¬¸ì¥ ë¹„êµ ìˆ˜í–‰

---

## âœ… Conclusion

- ë°ì´í„° ì‚¬ìš©ëŸ‰ ì¦ê°€ê°€ ëª¨ë¸ ì„±ëŠ¥ì— **ì§ì ‘ì ì¸ ì˜í–¥**ì„ ë¯¸ì¹¨
- A3Netì€ **ë¦¬í¬íŠ¸ ë‚´ í•´ë¶€í•™ì  ì¼ê´€ì„±** ì¸¡ë©´ì—ì„œ ìš°ìˆ˜í•œ ê²°ê³¼ë¥¼ ë³´ì„
- í–¥í›„ ë” ë³µí•©ì ì¸ Transformer êµ¬ì¡°ë‚˜ VLM ëª¨ë¸ ê²°í•© ê°€ëŠ¥ì„± ì¡´ì¬

---

## ğŸš€ Future Work

- ViT-GPT ê¸°ë°˜ ë©€í‹°ëª¨ë‹¬ êµ¬ì¡° ë„ì…
- ë³‘ë³€ ì‹œê°í™” (Grad-CAM ë“±) ê¸°ë°˜ LLM ë¦¬í¬íŠ¸ ì •êµí™”
- ë‹¤ì–‘í•œ ì§ˆë³‘/í´ë˜ìŠ¤ì— ëŒ€í•œ generalization ì„±ëŠ¥ í™•ì¸

---

## ğŸ‘¨â€ğŸ’» Contributors

- ì„œì¬ì„ (Konyang Univ., Dept. of Artificial Intelligence)  
- ì¥ê·¼í˜ (Konyang Univ., Dept. of Artificial Intelligence)  

Contact:  
- vhvh1398@naver.com  
- forren0418@naver.com

---

## ğŸ“š References

1. M. Varol ArÄ±soy et al., *A vision attention driven Language framework for medical report generation*, Scientific Reports, 2025.  
2. L. Agarwal and B. Verma, *Advanced Chest X-Ray Analysis via Transformer-Based Image Descriptors*, arXiv:2504.16774  
3. Z. Chen et al., *Generating Radiology Reports via Memory-driven Transformer*, EMNLP, 2020  
4. Q. V. Nguyen et al., *Anatomical Attention Alignment*, arXiv:2505.07689  
5. A. Johnson et al., *MIMIC-CXR: A large publicly available database*, NeurIPS ML4H, 2019
